{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0186d57a",
   "metadata": {},
   "source": [
    "# Loan Approval AI Bias and Audit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4613f55",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bf0724",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "import shap\n",
    "from sklearn.metrics import accuracy_score, recall_score, auc,precision_score, classification_report, make_scorer, confusion_matrix, f1_score, precision_recall_curve, average_precision_score, roc_curve\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce2ac00",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79659b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import datasets\n",
    "df1 = pd.read_csv('loan_access_dataset.csv')\n",
    "df = df1.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707ed5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801b168b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check dataset information and data types.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086d59e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check data summary\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953d4e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check missing values\n",
    "print(df.isnull().sum())\n",
    "print(test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcac4420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify and check for duplicates\n",
    "duplicates = df[df.duplicated()]\n",
    "duplicates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa0e0c0",
   "metadata": {},
   "source": [
    "## Data Preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f000b2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Map target feature (Loan_Approved) to 0 and 1\n",
    "df['Loan_Approved'] = df['Loan_Approved'].map({'Approved': 1, 'Denied': 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cfca5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check values count and proportions for categorical features\n",
    "cat_cols = ['Gender', 'Race', 'Citizenship_Status', 'Disability_Status', 'Criminal_Record', 'Age_Group', 'Zip_Code_Group', 'Language_Proficiency']\n",
    "\n",
    "for col in cat_cols:\n",
    "    print(f'\\n --- {col} (Counts and Proportions) ---')\n",
    "    print(df[col].value_counts(normalize=False))\n",
    "    print(df[col].value_counts(normalize=True).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7442f554",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot a pie chart to show target value distribution \n",
    "class_counts = df['Loan_Approved'].value_counts()\n",
    "\n",
    "sizes = class_counts.values\n",
    "labels = ['Denied' if val == 0 else 'Approved' for val in class_counts.index]\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.pie(sizes,labels=labels, autopct='%.1f%%', startangle=45, colors= ['skyblue', 'lightcoral'])\n",
    "\n",
    "plt.title('Distribution of Loan Approval')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c924261",
   "metadata": {},
   "outputs": [],
   "source": [
    "#investigate numerical columns using box-plots\n",
    "num_cols = ['Age', 'Income', 'Credit_Score', 'Loan_Amount']\n",
    "\n",
    "plt.figure(figsize=(5 * len(num_cols), 6))\n",
    "\n",
    "for i, col in enumerate(num_cols, 1):\n",
    "    plt.subplot (1, len(num_cols), i) \n",
    "    sns.boxplot(y=df[col])\n",
    "    plt.title(f'{col} Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1e492b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a temporary dataset to visualize correlation\n",
    "temp_df = df1.copy()\n",
    "\n",
    "## Find the categorical columns\n",
    "categorical_columns = temp_df.select_dtypes(include=['object']).columns\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "for col in categorical_columns:\n",
    "    temp_df[col] = label_encoder.fit_transform(temp_df[col].astype(str))\n",
    "\n",
    "temp_df =temp_df.drop('ID', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff19f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##visualize correlation\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(temp_df.corr(method='spearman'), annot=True, fmt='.2f', cmap='coolwarm', annot_kws={'fontsize': 10}, vmin=-1, vmax=1, center=0)\n",
    "plt.title('Loan Approval Heatmap')\n",
    "#plt.savefig('heatmap of Loan features.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc3c1f9",
   "metadata": {},
   "source": [
    "#### Exploring Bias in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a3caf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot Loan approval by different groups\n",
    "def approval_by_group(df, group_column):\n",
    "    \"\"\"\n",
    "    This function plots proportion of loan approval rates by demographics\n",
    "    \"\"\"\n",
    "    group_counts = df.groupby([group_column, 'Loan_Approved']).size().unstack(fill_value=0)\n",
    "    group_props = group_counts.div(group_counts.sum(axis=1), axis=0)\n",
    "\n",
    "    \n",
    "    group_props.columns = ['Denied', 'Approved']\n",
    "    colors = sns.color_palette('husl', n_colors=2)\n",
    "\n",
    "    group_props = group_props.sort_values(by='Approved', ascending=False)\n",
    "\n",
    "    ax = group_props.plot(kind='bar', stacked=True, figsize=(8, 5), color=colors)\n",
    "    for i, (index,row) in enumerate (group_props.iterrows()):\n",
    "        denied =row['Denied']\n",
    "        approved = row['Approved']\n",
    "        ax.text(i, denied + approved / 2, f\"{approved:.0%}\", ha='center', va='center', color='white', fontsize=10)\n",
    "\n",
    "\n",
    "    plt.title(f'Loan Approval Rate by {group_column}')\n",
    "    plt.ylabel('Proportion')\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763f8bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## call approval_by_group\n",
    "approval_by_group(df, 'Gender')\n",
    "approval_by_group(df, 'Race')\n",
    "approval_by_group(df, 'Disability_Status')\n",
    "approval_by_group(df, 'Criminal_Record')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9430930b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a new feature (credit score group), and visualize\n",
    "# loan approval rate by credit score group and\n",
    "# bin credit scores with FICO credit score.\n",
    "# FICO is a tool used to determine if a person qualifies for a \n",
    "## credit card, mortgage , or other loan.\n",
    "\n",
    "bins = [300, 579, 669, 739, 799, float('inf')]\n",
    "labels = ['Poor', 'Fair', 'Good', 'Very Good', 'Excellent']\n",
    "df['CreditScore_Group'] = pd.cut(df['Credit_Score'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "# approval rate by group (CreditScore_Group Ã— Race)\n",
    "grouped = df.groupby(['CreditScore_Group', 'Race'])['Loan_Approved'].mean().unstack()\n",
    "\n",
    "# Plot bar chart for grouped\n",
    "grouped.plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Loan Approval Rate by Credit Score Group and Race')\n",
    "plt.ylabel('Approval Rate')\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel('Credit Score Group')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title='Race', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c2a0ed",
   "metadata": {},
   "source": [
    "#### Bias detection on an individual basis (training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe214e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ========================================================\n",
    "## Bias Detection: Inspection of Bias on an Individual Basis\n",
    "## =========================================================\n",
    "# Some cases are suspicious so they will be flagged e.g high credit score, loan denied\n",
    "## define limits \n",
    "\n",
    "high_credit = df['Credit_Score'].quantile(0.85)\n",
    "low_credit = df['Credit_Score'].quantile(0.15)\n",
    "high_income = df['Income'].quantile(0.85)\n",
    "low_income = df['Income'].quantile(0.15)\n",
    "\n",
    "## function to flag those cases\n",
    "def abnormal_cases(df, high_credit, low_credit, high_income, low_income):\n",
    "    \"\"\"\n",
    "    this function flags suspicious cases where:\n",
    "    1. High credit score but denied\n",
    "    2. Low credit score but approved\n",
    "    3. High income but denied\n",
    "    4. Low income but approved.\n",
    "    \"\"\"\n",
    "    # Create boolean flags for each abnormal condition\n",
    "    high_credit_denied = (df['Credit_Score'] > high_credit) & (df['Loan_Approved'] == 0)\n",
    "    low_credit_approved = (df['Credit_Score'] < low_credit) & (df['Loan_Approved'] == 1)\n",
    "    high_income_denied = (df['Income'] > high_income) & (df['Loan_Approved'] == 0)\n",
    "    low_income_approved = (df['Income'] < low_income) & (df['Loan_Approved'] == 1)\n",
    "\n",
    "\n",
    "    df['Suspicious'] = high_credit_denied | low_credit_approved | high_income_denied | low_income_approved\n",
    "    # Return only suspicious rows for review\n",
    "    return df[df['Suspicious'] == True].sort_values(by='Credit_Score', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dbcf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## call the function\n",
    "abnormal = abnormal_cases(df, high_credit, low_credit, high_income, low_income)\n",
    "abnormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4409b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop irrelevant features and new features that were created\n",
    "df = df.drop(columns=['ID', 'Age_Group', 'CreditScore_Group', 'Suspicious'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c57329c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to csv for review\n",
    "abnormal.to_csv('Individual_cases_for review.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497fb773",
   "metadata": {},
   "source": [
    "## Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78874846",
   "metadata": {},
   "source": [
    "######\n",
    " I will be training two models. One where I exclude the  sensitive features to remove any \n",
    " form of bias then another one where I include sensitive  features for bias auditing.\n",
    " sensitive features (Race, Gender, Disability_Status etc).  I will then compare both.\n",
    "######\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de0673d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Forest will be used to develop the models\n",
    "# Define the model. \n",
    "#for sensitive\n",
    "rf_s = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "#for insensitive\n",
    "rf_n = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e6f132",
   "metadata": {},
   "source": [
    "##### Define sensitive and non-sensitive features ('s'represents sensitive, 'ns' represents non-sensitive) Group features into sensitive and predictive( what is exactly needed for a loan prediction)\n",
    "##### \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb298fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sensitive_features = ['Gender', 'Race', 'Citizenship_Status','Language_Proficiency', \n",
    "                      'Criminal_Record', 'Zip_Code_Group'] \n",
    "predictive_features = ['Age','Income', 'Credit_Score', 'Loan_Amount',\n",
    "                      'Employment_Type', 'Education_Level']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d79f621",
   "metadata": {},
   "outputs": [],
   "source": [
    "## =======================\n",
    "# Model with sensitive features:The steps below are for the model that contains sensitive attributes.\n",
    "#=========================\n",
    "# define features for training \n",
    "num_cols_s = ['Age', 'Income','Credit_Score','Loan_Amount']\n",
    "cat_cols_s = ['Gender','Race','Employment_Type','Education_Level',\n",
    "                   'Citizenship_Status','Language_Proficiency','Disability_Status',\n",
    "                    'Criminal_Record','Zip_Code_Group' ]\n",
    "\n",
    "#define X and y train\n",
    "X_s= df[num_cols_s + cat_cols_s]\n",
    "y_target= df['Loan_Approved']\n",
    "\n",
    "#split dataframe with stratified sampling\n",
    "train_idx, val_idx = train_test_split(\n",
    "    df.index, test_size=0.2, stratify=df['Loan_Approved'], random_state=42\n",
    ")\n",
    "\n",
    "X_train_s = df.loc[train_idx, num_cols_s + cat_cols_s]\n",
    "X_val_s = df.loc[val_idx,num_cols_s + cat_cols_s]\n",
    "y_train_s = df.loc[train_idx, 'Loan_Approved']\n",
    "y_val_s = df.loc[val_idx, 'Loan_Approved']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b68ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical columns are to be encoded\n",
    "categorical_transformer_s = Pipeline([\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "#numerical columns are not being scaled because random forest is a tree based model and can handle the values\n",
    "\n",
    "\n",
    "preprocessor_s = ColumnTransformer([\n",
    "    ('num', 'passthrough', num_cols_s),\n",
    "    ('cat', categorical_transformer_s, cat_cols_s)\n",
    "])\n",
    "\n",
    "# random forest pipeline for model with sensitive features\n",
    "rf_pipeline_s = Pipeline([\n",
    "    ('preprocessor_s', preprocessor_s),\n",
    "    ('model_s', rf_s)\n",
    "])\n",
    "\n",
    "#train and evaluate random forest on model with sensistive features\n",
    "rf_pipeline_s.fit(X_train_s, y_train_s)\n",
    "rf_preds_s = rf_pipeline_s.predict(X_val_s)\n",
    "rf_probs_s = rf_pipeline_s.predict_proba(X_val_s)[:, 1]\n",
    "\n",
    "print(\"--- Random Forest Results For Model with Sensitive Features ---\")\n",
    "print(classification_report(y_val_s, rf_preds_s))\n",
    "print(\"AUC:\", roc_auc_score(y_val_s, rf_probs_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbce4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## =======================\n",
    "# Model without sensitive features:The steps below are for the model that do not contain sensitive attributes.\n",
    "# The features used for modeling are: Age,Income, 'redit_Score, Loan_Amount, Employment_Type, Education_Level\n",
    "#validation set will be used to see the model's performance while X test is \n",
    "#used only for prediction\n",
    "#=========================\n",
    "# define features for training \n",
    "\n",
    "num_cols_n = ['Age', 'Income','Credit_Score','Loan_Amount']\n",
    "cat_cols_n = ['Employment_Type','Education_Level']\n",
    "\n",
    "# define x and y\n",
    "X_n = df[num_cols_n + cat_cols_n]\n",
    "y_target = df['Loan_Approved']\n",
    "\n",
    "#data has been split above. Reusing indices\n",
    "X_train_n = df.loc[train_idx, num_cols_n + cat_cols_n]\n",
    "X_val_n = df.loc[val_idx,num_cols_n + cat_cols_n]\n",
    "y_train_n = df.loc[train_idx, 'Loan_Approved']\n",
    "y_val_n = df.loc[val_idx, 'Loan_Approved']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966fb3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical columns to be encoded\n",
    "categorical_transformer_n = Pipeline([\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor_n = ColumnTransformer([\n",
    "    ('num', 'passthrough', num_cols_n),\n",
    "    ('cat', categorical_transformer_n, cat_cols_n)\n",
    "    ])\n",
    "\n",
    "#define X test\n",
    "X_test = test[num_cols_n + cat_cols_n]\n",
    "\n",
    "rf_pipeline_n = Pipeline([\n",
    "    ('preprocess_n',preprocessor_n ),\n",
    "    ('model_n', rf_n)\n",
    "])\n",
    "\n",
    "#Train and evaluate Random Forest on model without sensitive features\n",
    "rf_pipeline_n.fit(X_train_n, y_train_n)\n",
    "rf_preds_n = rf_pipeline_n.predict(X_val_n)\n",
    "rf_probs_n = rf_pipeline_n.predict_proba(X_val_n)[:, 1]\n",
    "\n",
    "print('--- Random Forest Results for Model without Sensitive Features ---')\n",
    "print(classification_report(y_val_n, rf_preds_n))\n",
    "print(\"AUC:\", roc_auc_score(y_val_n, rf_probs_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564e8a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for the baseline model prediction\n",
    "#Re-train random forest on full train dataset\n",
    "X_full_train = df[num_cols_n + cat_cols_n]\n",
    "y_full_train = df['Loan_Approved']\n",
    "\n",
    "rf_pipeline_n.fit(X_full_train, y_full_train)\n",
    "\n",
    "test_preds_n = rf_pipeline_n.predict(X_test)\n",
    "\n",
    "#add prediction values to submission file\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test['ID'],\n",
    "    'Loan_Approved': test_preds_n\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ec14af",
   "metadata": {},
   "source": [
    "#### SHAP analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d0e8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two plots will be plotted (one for the sensitive and non sensitive models each)\n",
    "\n",
    "\n",
    "#for sensitive\n",
    "# Extract the preprocessor and model from the pipeline\n",
    "preprocessor_s = rf_pipeline_s.named_steps['preprocessor_s']\n",
    "model_s = rf_pipeline_s.named_steps['model_s']\n",
    "\n",
    "# Transform X_val_s for SHAP analysis\n",
    "X_val_s_transformed = preprocessor_s.transform(X_val_s)\n",
    "\n",
    "# Get transformed feature names\n",
    "feature_names_s = preprocessor_s.get_feature_names_out()\n",
    "\n",
    "# Create a DataFrame for SHAP with feature names (this is to keep full names for consistency with pipeline)\n",
    "X_val_s_df = pd.DataFrame(X_val_s_transformed.toarray() if hasattr(X_val_s_transformed, 'toarray') else X_val_s_transformed,\n",
    "                          columns=feature_names_s,\n",
    "                          index=X_val_s.index)\n",
    "\n",
    "# Train SHAP explainer and compute values\n",
    "explainer_s = shap.TreeExplainer(model_s)\n",
    "shap_values_s = explainer_s.shap_values(X_val_s_df)\n",
    "shap_class_1_s = shap_values_s[:, :, 1]\n",
    "\n",
    "# clean feature names for plotting only (remove 'cat' in front of labels for readability)\n",
    "clean_names_s = [name.replace('cat__', '').replace('num__', '').replace('remainder__', '') for name in feature_names_s]\n",
    "\n",
    "\n",
    "# Plot SHAP summary\n",
    "shap.summary_plot(shap_class_1_s, X_val_s_df, feature_names=clean_names_s, show=False)\n",
    "\n",
    "plt.title('SHAP Summary: Sensitive Model')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eadea64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for non sensistive\n",
    "# Extract the preprocessor and model from the pipeline\n",
    "preprocessor_n = rf_pipeline_n.named_steps['preprocess_n']\n",
    "model_n = rf_pipeline_n.named_steps['model_n']\n",
    "\n",
    "# Transform X_val_n for SHAP analysis\n",
    "X_val_n_transformed = preprocessor_n.transform(X_val_n)\n",
    "\n",
    "# Get transformed feature names\n",
    "feature_names_n = preprocessor_n.get_feature_names_out()\n",
    "\n",
    "# Create a DataFrame for SHAP with feature names (keep full names for group prediction later)\n",
    "X_val_n_df = pd.DataFrame(X_val_n_transformed.toarray() if hasattr(X_val_n_transformed, 'toarray') else X_val_n_transformed,\n",
    "                          columns=feature_names_n,\n",
    "                          index=X_val_n.index)\n",
    "\n",
    "# Train a SHAP explainer and compute values\n",
    "explainer_n = shap.TreeExplainer(model_n)\n",
    "shap_values_n = explainer_n.shap_values(X_val_n_df)\n",
    "shap_class_1_n = shap_values_n[:, :, 1]\n",
    "\n",
    "# clean feature names for plotting only\n",
    "clean_names_n = [name.replace('cat__', '').replace('num__', '').replace('remainder__', '') for name in feature_names_n]\n",
    "\n",
    "# Plot SHAP summary\n",
    "shap.summary_plot(shap_class_1_n, X_val_n_df, feature_names=clean_names_n, show=False)\n",
    "\n",
    "plt.title('SHAP Summary: Non-sensitive Model')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf66359",
   "metadata": {},
   "source": [
    "##### Plot Approval Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a1f763",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the rate of approval for each group\n",
    "# get sensitive features for the validation set\n",
    "val_sensitive = df.loc[X_val_n.index, ['Gender', 'Race', 'Disability_Status', 'Criminal_Record']]\n",
    "\n",
    "# make predictions on the preprocessed validation set\n",
    "val_preds = rf_pipeline_n.predict(X_val_n)\n",
    "\n",
    "val_sensitive_preds = val_sensitive.copy()\n",
    "val_sensitive_preds['Predicted_Loan_Approval'] = val_preds\n",
    "\n",
    "# compute approval rates by group\n",
    "# Gender\n",
    "gender_approval = val_sensitive_preds.groupby('Gender')['Predicted_Loan_Approval'].mean().reset_index()\n",
    "print('\\nApproval Rates by Gender:\\n', gender_approval)\n",
    "\n",
    "# Race\n",
    "race_approval = val_sensitive_preds.groupby('Race')['Predicted_Loan_Approval'].mean().reset_index()\n",
    "print(\"\\nApproval Rates by Race:\\n\", race_approval)\n",
    "\n",
    "# Disability Status\n",
    "disability_approval = val_sensitive_preds.groupby('Disability_Status')['Predicted_Loan_Approval'].mean().reset_index()\n",
    "print(\"\\nApproval Rates by Disability Status:\\n\", disability_approval)\n",
    "\n",
    "\n",
    "# Criminal Record\n",
    "Criminal_record_approval = val_sensitive_preds.groupby('Criminal_Record')['Predicted_Loan_Approval'].mean().reset_index()\n",
    "print(\"\\nApproval Rates by Criminal Record:\\n\", Criminal_record_approval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6712ea74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot bar charts for approval rates\n",
    "# Dictionary to map groups names to the approval rate DataFrames above\n",
    "group_data = {\n",
    "    'Gender': gender_approval,\n",
    "    'Race': race_approval,\n",
    "    'Disability_Status': disability_approval,\n",
    "    'Criminal_Record': Criminal_record_approval\n",
    "}\n",
    "\n",
    "# Loop through each group and plot\n",
    "for group, data in group_data.items():\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    ax = sns.barplot(x=group, y='Predicted_Loan_Approval', data=data, palette='pastel')\n",
    "    plt.title(f'Loan Approval Rate by {group}')\n",
    "    plt.ylabel('Approval Rate')\n",
    "    plt.ylim(0, 1)\n",
    "\n",
    "   \n",
    "    for p in ax.patches:\n",
    "        height = p.get_height()\n",
    "        ax.text(p.get_x() + p.get_width() / 2, height + 0.02, f'{height:.1%}', ha='center')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4afacc3",
   "metadata": {},
   "source": [
    "##### False Positive (FPR) and False Negative Rate (FNR) Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e5514c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate FPR and FNR for each group\n",
    "def compute_error_rates(df, group_col, y_true, y_pred):\n",
    "    \"\"\"this function calculates the false\n",
    "    positive rate and false negative rate for\n",
    "    each group\"\"\"\n",
    "    results = []\n",
    "    for group in df[group_col].unique():\n",
    "        idx = df[group_col] == group\n",
    "        y_true_group = y_true[idx]\n",
    "        y_pred_group = y_pred[idx]\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true_group, y_pred_group, labels=[0, 1]).ravel()\n",
    "        fpr = fp / (fp + tn) if (fp + tn) != 0 else 0\n",
    "        fnr = fn / (fn + tp) if (fn + tp) != 0 else 0\n",
    "\n",
    "        results.append({'Group': group, 'FPR': round(fpr, 3), 'FNR': round(fnr, 3)})\n",
    "    \n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca404fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to each sensitive groups\n",
    "val_sensitive_preds['True_Label'] = y_val_n  # y_val_n is your true labels\n",
    "groups = ['Gender', 'Race', 'Disability_Status', 'Criminal_Record']\n",
    "\n",
    "for group_col in groups:\n",
    "    print(f\"\\nError rates for {group_col}:\")\n",
    "    error_df = compute_error_rates(val_sensitive_preds, group_col,\n",
    "                                   val_sensitive_preds['True_Label'],\n",
    "                                   val_sensitive_preds['Predicted_Loan_Approval'])\n",
    "    print(error_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59fdf47",
   "metadata": {},
   "source": [
    "##### Plot bar charts for FPR and NPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc4a714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of groups and their titles\n",
    "groups = ['Gender', 'Race']\n",
    "error_types = ['FPR', 'FNR']\n",
    "\n",
    "for group_col in groups:\n",
    "    # Get error rates for this group\n",
    "    error_df = compute_error_rates(val_sensitive_preds, group_col,\n",
    "                                   val_sensitive_preds['True_Label'],\n",
    "                                   val_sensitive_preds['Predicted_Loan_Approval'])\n",
    "    \n",
    "    # For each error type (FPR and FNR), plot a bar chart\n",
    "    for error_type in error_types:\n",
    "        plt.figure(figsize=(7, 4))\n",
    "        ax = sns.barplot(x='Group', y=error_type, data=error_df, palette='pastel')\n",
    "\n",
    "        # Add value labels on bars\n",
    "        for p in ax.patches:\n",
    "            height = p.get_height()\n",
    "            ax.text(p.get_x() + p.get_width() / 2, height + 0.02, f'{height:.2f}', ha='center', fontsize=9)\n",
    "\n",
    "        plt.title(f'{error_type} by {group_col}')\n",
    "        plt.ylabel('Error Rate')\n",
    "        plt.ylim(0, max(error_df[error_type]) + 0.1)\n",
    "        plt.xticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
